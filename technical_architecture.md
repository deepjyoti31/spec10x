# Spec10x â€” Technical Architecture Plan

> **Principles:** Simple. Open-source first. GCP-native (Vertex AI). Scales from v0.1 to v1.0 without rewriting.

---

## 1. Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              FRONTEND                                    â”‚
â”‚                    Next.js (React + TypeScript)                           â”‚
â”‚                     Deployed on Cloud Run                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚ HTTPS / WebSocket
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              BACKEND                                     â”‚
â”‚                    FastAPI (Python 3.12+)                                â”‚
â”‚                     Deployed on Cloud Run                                â”‚
â”‚                                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  REST API   â”‚  â”‚  WebSocket  â”‚  â”‚  Background  â”‚  â”‚   Auth       â”‚  â”‚
â”‚  â”‚  Endpoints  â”‚  â”‚  Server     â”‚  â”‚  Workers     â”‚  â”‚   (Firebase) â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                â”‚                â”‚
  â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚                        DATA LAYER                                â”‚
  â”‚                                                                  â”‚
  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
  â”‚  â”‚ PostgreSQL   â”‚  â”‚  Redis   â”‚  â”‚  Google Cloud Storage    â”‚  â”‚
  â”‚  â”‚ + pgvector   â”‚  â”‚  (Queue  â”‚  â”‚  (File uploads)          â”‚  â”‚
  â”‚  â”‚ (Cloud SQL)  â”‚  â”‚  + Cache)â”‚  â”‚                          â”‚  â”‚
  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
  â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚                        AI LAYER                                 â”‚
  â”‚                                                                  â”‚
  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
  â”‚  â”‚  Vertex AI       â”‚  â”‚  Vertex AI       â”‚  â”‚  FFmpeg     â”‚  â”‚
  â”‚  â”‚  Gemini 3.1      â”‚  â”‚  Chirp 3         â”‚  â”‚  (video â†’   â”‚  â”‚
  â”‚  â”‚  Flash + Embed   â”‚  â”‚  (transcription)  â”‚  â”‚   audio)    â”‚  â”‚
  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2. Technology Stack

### Why Each Choice

| Layer | Technology | Why This | Open-Source? |
|---|---|---|---|
| **Frontend** | Next.js 16.1 (React 19 + TypeScript) | SSR for landing page SEO, SPA for the app, Turbopack stable, huge ecosystem | âœ… |
| **Backend** | FastAPI (Python 3.12+) | Best AI/ML ecosystem, async-native, type-safe, first-class Vertex AI SDK | âœ… |
| **Database** | PostgreSQL 18 + pgvector 0.8 | One DB for relational data AND vector search. No separate vector DB needed | âœ… |
| **Cache / Queue** | Redis 8.x | Job queue (via `arq` or `Celery`), caching, pub/sub for WebSocket coordination | âœ… |
| **File Storage** | Google Cloud Storage | Cheap, reliable, direct upload from browser via signed URLs | GCP |
| **Video â†’ Audio** | FFmpeg (open-source) | Extract audio track from video files before transcription | âœ… |
| **AI â€” Extraction** | Gemini 2.5 Flash-Lite (via Vertex AI) | $0.10/1M input tokens â€” 5x cheaper than Gemini 3 Flash. Sufficient quality for theme extraction | GCP |
| **AI â€” Q&A** | Gemini 3 Flash (via Vertex AI) | Higher quality for user-facing answers. $0.50/1M input tokens | GCP |
| **AI â€” Embeddings** | gemini-embedding-001 (via Vertex AI) | Top MTEB scores, 100+ languages, default 3072 dims (scalable to 768 via MRL) | GCP |
| **AI â€” Transcription** | Chirp 3 (via Vertex AI STT V2) | GA (Oct 2025), speaker diarization, 85+ languages, built-in denoiser. $0.016/min | GCP |
| **Auth** | Firebase Authentication | GCP-native, email + Google OAuth, free tier generous | GCP (free) |
| **Payments** | Stripe | Industry standard for SaaS billing, great API | N/A |
| **Deployment** | Cloud Run | Serverless containers, scales to zero, no K8s to manage, native custom domains with auto-SSL | GCP |
| **Database Hosting** | Cloud SQL (PostgreSQL 18) | Managed, auto-backups, pgvector 0.8.1 supported | GCP |
| **Redis Hosting** | Memorystore for Redis | Managed Redis on GCP | GCP |
| **Monitoring** | Cloud Logging + Sentry (errors) | GCP-native logging + open-source error tracking | Sentry: âœ… |

> **Model Selection Strategy:** We use a two-tier approach to balance cost and quality:
> - **Gemini 2.5 Flash-Lite** for bulk extraction tasks (theme/insight extraction from transcripts) â€” these run in background workers and donâ€™t need the absolute best quality. At $0.10/1M tokens, itâ€™s 5x cheaper than Gemini 3 Flash.
> - **Gemini 3 Flash** for user-facing Q&A responses (the â€œAskâ€ feature) â€” these need higher quality since users directly read and evaluate them. At $0.50/1M tokens, still affordable given low query volume.
> - **Can upgrade later:** If Gemini 3 Flash-Lite launches (expected), weâ€™ll switch extraction to that for even better quality at the same cost.

> **Embedding Dimensions:** gemini-embedding-001 defaults to 3072 dimensions but supports Matryoshka Representation Learning (MRL) â€” we can set output dimensions to 768 to reduce storage and improve pgvector query speed with minimal quality loss. This is a config parameter, not a code change.

### What We're NOT Using (and Why)

| Skipped | Why |
|---|---|
| **Cloud DNS** | Using GoDaddy DNS â€” just point A/CNAME records to Cloud Run. No need for a separate DNS service |
| **Cloud Load Balancer** | Not needed for beta (50-100 users). Cloud Run handles HTTPS and auto-SSL natively via custom domain mapping. Revisit when scaling past ~1K concurrent users |
| **Separate vector DB** (Pinecone, Weaviate) | pgvector handles our scale in v0.1-v0.5. Can migrate later if needed |
| **GraphQL** | REST is simpler; we don't have deeply nested data queries yet |
| **Kubernetes/GKE** | Cloud Run is enough. No need for K8s complexity until v1.0 scale |
| **Microservices** | Monolith backend with clear module boundaries. Split later if needed |
| **LangChain** | Over-abstraction for our use case. Direct Vertex AI SDK is simpler and more controllable |
| **Supabase** | Would add a dependency; we want direct control over our PostgreSQL schema |

---

## 3. Project Structure (Monorepo)

```
spec10x/
â”œâ”€â”€ frontend/                    # Next.js app
â”‚   â”œâ”€â”€ app/                     # App router pages
â”‚   â”‚   â”œâ”€â”€ (auth)/              # Login, signup
â”‚   â”‚   â”œâ”€â”€ (app)/               # Protected app pages
â”‚   â”‚   â”‚   â”œâ”€â”€ dashboard/       # Insight Dashboard
â”‚   â”‚   â”‚   â”œâ”€â”€ interview/[id]/  # Interview Detail
â”‚   â”‚   â”‚   â””â”€â”€ ask/             # Ask Your Interviews
â”‚   â”‚   â””â”€â”€ (marketing)/         # Landing page
â”‚   â”œâ”€â”€ components/              # Reusable UI components
â”‚   â”‚   â”œâ”€â”€ ui/                  # Primitives (Button, Card, Input, etc.)
â”‚   â”‚   â”œâ”€â”€ layout/              # NavBar, Sidebar, Panels
â”‚   â”‚   â”œâ”€â”€ dashboard/           # Theme cards, interview list
â”‚   â”‚   â”œâ”€â”€ interview/           # Transcript viewer, highlights
â”‚   â”‚   â”œâ”€â”€ ask/                 # Chat messages, citations
â”‚   â”‚   â””â”€â”€ upload/              # Upload modal, processing queue
â”‚   â”œâ”€â”€ lib/                     # API client, auth helpers, utils
â”‚   â”œâ”€â”€ hooks/                   # Custom React hooks
â”‚   â””â”€â”€ styles/                  # Global CSS, design tokens
â”‚
â”œâ”€â”€ backend/                     # FastAPI app
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py              # FastAPI app entry
â”‚   â”‚   â”œâ”€â”€ api/                 # API route modules
â”‚   â”‚   â”‚   â”œâ”€â”€ interviews.py    # Upload, list, delete, detail
â”‚   â”‚   â”‚   â”œâ”€â”€ themes.py        # List, rename, detail
â”‚   â”‚   â”‚   â”œâ”€â”€ insights.py      # CRUD, manual corrections
â”‚   â”‚   â”‚   â”œâ”€â”€ ask.py           # Q&A streaming endpoint
â”‚   â”‚   â”‚   â”œâ”€â”€ export.py        # Markdown/PDF export
â”‚   â”‚   â”‚   â””â”€â”€ billing.py       # Stripe webhooks, usage
â”‚   â”‚   â”œâ”€â”€ services/            # Business logic
â”‚   â”‚   â”‚   â”œâ”€â”€ processing.py    # File processing pipeline
â”‚   â”‚   â”‚   â”œâ”€â”€ transcription.py # Speech-to-text
â”‚   â”‚   â”‚   â”œâ”€â”€ analysis.py      # Gemini theme extraction
â”‚   â”‚   â”‚   â”œâ”€â”€ embeddings.py    # Vector embedding + storage
â”‚   â”‚   â”‚   â”œâ”€â”€ synthesis.py     # Cross-interview clustering
â”‚   â”‚   â”‚   â”œâ”€â”€ qa.py            # RAG-based Q&A
â”‚   â”‚   â”‚   â””â”€â”€ export.py        # Export formatting
â”‚   â”‚   â”œâ”€â”€ models/              # SQLAlchemy ORM models
â”‚   â”‚   â”œâ”€â”€ schemas/             # Pydantic request/response schemas
â”‚   â”‚   â”œâ”€â”€ workers/             # Background job definitions
â”‚   â”‚   â”œâ”€â”€ core/                # Config, auth, database setup
â”‚   â”‚   â””â”€â”€ prompts/             # Gemini prompt templates
â”‚   â”œâ”€â”€ alembic/                 # Database migrations
â”‚   â””â”€â”€ tests/
â”‚
â”œâ”€â”€ infra/                       # Terraform / deployment configs
â”‚   â”œâ”€â”€ terraform/               # GCP infrastructure as code
â”‚   â”œâ”€â”€ cloudbuild.yaml          # CI/CD pipeline
â”‚   â””â”€â”€ Dockerfile.backend       # Backend container
â”‚
â””â”€â”€ docs/                        # Architecture docs, ADRs
```

---

## 4. Data Model (PostgreSQL)

### Core Tables

```sql
-- Users & Auth
users
â”œâ”€â”€ id (UUID, PK)
â”œâ”€â”€ firebase_uid (VARCHAR, unique)  -- from Firebase Auth
â”œâ”€â”€ email (VARCHAR, unique)
â”œâ”€â”€ name (VARCHAR)
â”œâ”€â”€ avatar_url (VARCHAR)
â”œâ”€â”€ plan (ENUM: free, pro, business)
â”œâ”€â”€ stripe_customer_id (VARCHAR)
â”œâ”€â”€ created_at, updated_at

-- Interviews (the raw source material)
interviews
â”œâ”€â”€ id (UUID, PK)
â”œâ”€â”€ user_id (FK â†’ users)
â”œâ”€â”€ filename (VARCHAR)              -- original uploaded filename
â”œâ”€â”€ file_type (ENUM: txt, md, pdf, docx, mp3, wav, mp4)
â”œâ”€â”€ file_size_bytes (BIGINT)
â”œâ”€â”€ storage_path (VARCHAR)          -- GCS path
â”œâ”€â”€ status (ENUM: queued, transcribing, analyzing, done, error)
â”œâ”€â”€ transcript (TEXT)               -- full transcript text
â”œâ”€â”€ duration_seconds (INT)          -- for audio/video
â”œâ”€â”€ error_message (TEXT)
â”œâ”€â”€ metadata (JSONB)                -- flexible: { speakers: [...], language: "en" }
â”œâ”€â”€ file_hash (VARCHAR)             -- SHA-256 for duplicate detection
â”œâ”€â”€ created_at, updated_at

-- Speakers (participant metadata, optional)
speakers
â”œâ”€â”€ id (UUID, PK)
â”œâ”€â”€ interview_id (FK â†’ interviews)
â”œâ”€â”€ speaker_label (VARCHAR)         -- "Speaker 1" or detected name
â”œâ”€â”€ name (VARCHAR, nullable)        -- user-provided
â”œâ”€â”€ role (VARCHAR, nullable)
â”œâ”€â”€ company (VARCHAR, nullable)
â”œâ”€â”€ is_interviewer (BOOLEAN)
â”œâ”€â”€ auto_detected (BOOLEAN)

-- Themes (AI-discovered clusters)
themes
â”œâ”€â”€ id (UUID, PK)
â”œâ”€â”€ user_id (FK â†’ users)
â”œâ”€â”€ name (VARCHAR)                  -- AI-generated, user-renamable
â”œâ”€â”€ description (TEXT)              -- AI-generated summary
â”œâ”€â”€ mention_count (INT)             -- cached count
â”œâ”€â”€ sentiment_positive (FLOAT)      -- 0.0-1.0
â”œâ”€â”€ sentiment_neutral (FLOAT)
â”œâ”€â”€ sentiment_negative (FLOAT)
â”œâ”€â”€ is_new (BOOLEAN)                -- "NEW" badge flag
â”œâ”€â”€ last_new_activity (TIMESTAMP)   -- when last new quote was added
â”œâ”€â”€ status (ENUM: active, previous) -- active vs "Previous themes"
â”œâ”€â”€ created_at, updated_at

-- Sub-themes (children of themes)
sub_themes
â”œâ”€â”€ id (UUID, PK)
â”œâ”€â”€ theme_id (FK â†’ themes)
â”œâ”€â”€ name (VARCHAR)

-- Insights (individual extracted observations)
insights
â”œâ”€â”€ id (UUID, PK)
â”œâ”€â”€ user_id (FK â†’ users)
â”œâ”€â”€ interview_id (FK â†’ interviews)
â”œâ”€â”€ theme_id (FK â†’ themes)
â”œâ”€â”€ category (ENUM: pain_point, feature_request, positive, suggestion)
â”œâ”€â”€ title (VARCHAR)                 -- "Onboarding documentation is outdated"
â”œâ”€â”€ quote (TEXT)                    -- exact quoted text
â”œâ”€â”€ quote_start_index (INT)        -- position in transcript for highlighting
â”œâ”€â”€ quote_end_index (INT)
â”œâ”€â”€ speaker_id (FK â†’ speakers)
â”œâ”€â”€ confidence (FLOAT)             -- AI confidence 0.0-1.0
â”œâ”€â”€ is_flagged (BOOLEAN)           -- ğŸš© uncertain
â”œâ”€â”€ is_dismissed (BOOLEAN)         -- user dismissed
â”œâ”€â”€ is_manual (BOOLEAN)            -- user-created (not AI)
â”œâ”€â”€ created_at, updated_at

-- Transcript Chunks (for RAG / vector search)
transcript_chunks
â”œâ”€â”€ id (UUID, PK)
â”œâ”€â”€ interview_id (FK â†’ interviews)
â”œâ”€â”€ chunk_index (INT)              -- order within interview
â”œâ”€â”€ content (TEXT)                  -- chunk text (~500 tokens)
â”œâ”€â”€ embedding (VECTOR(768))        -- pgvector column (768 dims via MRL, down from default 3072)
â”œâ”€â”€ speaker_id (FK â†’ speakers, nullable)
â”œâ”€â”€ created_at

-- Ask Conversations (chat history)
ask_conversations
â”œâ”€â”€ id (UUID, PK)
â”œâ”€â”€ user_id (FK â†’ users)
â”œâ”€â”€ created_at

ask_messages
â”œâ”€â”€ id (UUID, PK)
â”œâ”€â”€ conversation_id (FK â†’ ask_conversations)
â”œâ”€â”€ role (ENUM: user, assistant)
â”œâ”€â”€ content (TEXT)
â”œâ”€â”€ citations (JSONB)              -- [{interview_id, quote, chunk_id}]
â”œâ”€â”€ created_at

-- Usage Tracking
usage
â”œâ”€â”€ id (UUID, PK)
â”œâ”€â”€ user_id (FK â†’ users)
â”œâ”€â”€ month (DATE)                   -- 2026-02-01
â”œâ”€â”€ interviews_uploaded (INT)
â”œâ”€â”€ qa_queries_used (INT)
â”œâ”€â”€ storage_bytes_used (BIGINT)
```

### Key Indexes

```sql
-- Vector similarity search (the core of "Ask Your Interviews")
CREATE INDEX ON transcript_chunks USING ivfflat (embedding vector_cosine_ops) WITH (lists = 100);

-- Fast lookups
CREATE INDEX ON insights (user_id, theme_id);
CREATE INDEX ON insights (interview_id);
CREATE INDEX ON interviews (user_id, status);
CREATE INDEX ON interviews (file_hash);  -- duplicate detection
CREATE INDEX ON themes (user_id, status);
```

---

## 5. Processing Pipeline (The Core Engine)

When a user uploads files, here's exactly what happens:

```
User drops files
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. UPLOAD   â”‚â”€â–¶â”‚ 2. EXTRACT     â”‚â”€â–¶â”‚ 3. TRANSCRIBEâ”‚â”€â–¶â”‚ 4. ANALYZE   â”‚
â”‚              â”‚  â”‚  AUDIO         â”‚  â”‚              â”‚  â”‚              â”‚
â”‚ Browser â†’    â”‚  â”‚ FFmpeg: video  â”‚  â”‚ Vertex AI    â”‚  â”‚ Vertex AI    â”‚
â”‚ Signed URL â†’ â”‚  â”‚ â†’ audio (.wav) â”‚  â”‚ Chirp 3      â”‚  â”‚ Gemini 2.5   â”‚
â”‚ GCS          â”‚  â”‚ (skip for text)â”‚  â”‚ (skip: text) â”‚  â”‚ Flash-Lite   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                                       â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. EMBED        â”‚â”€â”€â”€â”€â–¶â”‚  6. CLUSTER     â”‚â”€â”€â”€â”€â–¶â”‚  7. NOTIFY     â”‚
â”‚                  â”‚     â”‚                 â”‚     â”‚                â”‚
â”‚ Chunk transcript â”‚     â”‚ Cross-interview â”‚     â”‚ WebSocket â†’    â”‚
â”‚ â†’ gemini-embed   â”‚     â”‚ theme synthesis â”‚     â”‚ Update UI      â”‚
â”‚ â†’ pgvector       â”‚     â”‚ + merge themes  â”‚     â”‚                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Step-by-Step Detail

**Step 1 â€” Upload** (frontend-driven, fast)
- Frontend requests a signed upload URL from backend
- Frontend uploads directly to GCS (avoids backend bottleneck)
- Backend creates an `interviews` row with status `queued`
- A background job is enqueued in Redis

**Step 2 â€” Extract Audio** (background worker, video only)
- Worker picks up the job from Redis
- If text file (.txt, .md, .pdf, .docx): extract text directly â†’ skip to Step 4
- If audio file (.mp3, .wav): skip this step â†’ proceed to Step 3
- If video file (.mp4):
  - Use **FFmpeg** (open-source, installed in the worker container) to extract the audio track:
    ```bash
    ffmpeg -i input_video.mp4 -vn -acodec pcm_s16le -ar 16000 -ac 1 output.wav
    ```
    - `-vn` = discard video stream
    - `-acodec pcm_s16le` = uncompressed WAV (best for STT)
    - `-ar 16000` = 16kHz sample rate (optimal for Chirp 3)
    - `-ac 1` = mono (speech doesn't need stereo)
  - Upload extracted `.wav` to GCS (temp path), delete original video from GCS
  - This reduces storage costs significantly (a 100MB video â†’ ~10MB audio)
- WebSocket push: "File X: Audio extracted"

**Step 3 â€” Transcribe** (background worker, audio only)
- Send the audio file (original or extracted) to **Vertex AI Chirp 3**
  - Use Chirp 3 via the `google.cloud.speech_v2` SDK
  - Enable speaker diarization (auto-detect number of speakers)
  - Chirp 3 supports 100+ languages natively â€” no language detection needed
  - For long files: use `BatchRecognize` API for async processing
  - For short files (<1 min): use `Recognize` API for sync processing
- Save full transcript to DB
- Update interview status: `transcribing` â†’ `analyzing`
- WebSocket push: "File X: Transcription complete"

**Step 4 â€” Analyze** (background worker, Gemini call)
- Send full transcript to **Gemini 2.5 Flash-Lite** via Vertex AI with a structured extraction prompt
- Why Flash-Lite: This is batch background work, not user-facing. $0.10/1M tokens (5x cheaper than Gemini 3 Flash)
- Prompt asks for JSON output:

```json
{
  "insights": [
    {
      "category": "pain_point",
      "title": "Onboarding documentation is outdated",
      "quote": "The setup process took me almost an hour...",
      "quote_start": 245,
      "quote_end": 312,
      "speaker": "Speaker 1",
      "theme_suggestion": "Onboarding Friction",
      "sub_themes": ["Documentation", "Setup time"],
      "sentiment": "negative",
      "confidence": 0.92
    }
  ],
  "detected_speakers": [
    { "label": "Speaker 1", "likely_name": "Sarah Chen", "likely_role": "Product Manager" }
  ],
  "language": "en",
  "summary": "..."
}
```
- Gemini's structured output mode ensures valid JSON
- Save insights to DB, update speakers
- WebSocket push: "File X: 5 insights extracted"

**Step 5 â€” Embed** (background worker)
- Split transcript into ~500-token chunks with 50-token overlap
- Generate embeddings via **gemini-embedding-001** model on Vertex AI (output dim = 768 via MRL for optimal pgvector performance)
- Store in `transcript_chunks` table with pgvector
- This enables semantic search for the "Ask" feature

**Step 6 â€” Cluster/Synthesize** (background worker)
- After each new interview, re-run cross-interview synthesis
- Algorithm:
  1. Get all `theme_suggestion` values from all insights for this user
  2. Embed theme suggestions
  3. Cluster by cosine similarity (threshold: 0.85)
  4. For each cluster: create or update a `themes` row
  5. Link insights to themes
  6. Calculate sentiment aggregation per theme
  7. Mark new/emerging themes with `is_new = true`
- This is lightweight â€” runs in seconds for dozens of interviews

**Step 7 â€” Notify** (WebSocket)
- Push real-time updates to the frontend at every step
- Frontend updates the upload modal's live insight preview and processing queue
- When all files are done, enable the "View Insights" button

---

## 6. RAG Pipeline ("Ask Your Interviews")

```
User question: "What do users think about onboarding?"
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Embed query   â”‚  â†’ Vertex AI gemini-embedding-001 (768 dims) â†’ vector
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. Vector search â”‚  â†’ pgvector: SELECT * FROM transcript_chunks
â”‚                  â”‚    ORDER BY embedding <=> query_embedding
â”‚                  â”‚    LIMIT 20
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. Re-rank       â”‚  â†’ Optional: Gemini re-ranks by relevance
â”‚    (optional)    â”‚    Keeps top 10 most relevant chunks
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. Generate      â”‚  â†’ Vertex AI Gemini 3 Flash (higher quality for user-facing answers):
â”‚    answer        â”‚    System: "You are an interview analyst..."
â”‚                  â”‚    Context: [10 transcript chunks with sources]
â”‚                  â”‚    User: "What do users think about onboarding?"
â”‚                  â”‚    â†’ Structured output with citations
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. Stream to UI  â”‚  â†’ Server-Sent Events (SSE)
â”‚                  â”‚    Token-by-token streaming
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Answer Format (Gemini output)

```json
{
  "answer": "Based on 12 interviews, **onboarding** was the most...",
  "citations": [
    {
      "interview_id": "uuid-1",
      "speaker_name": "Sarah Chen",
      "quote": "The setup process took me almost an hour...",
      "chunk_id": "uuid-chunk-5"
    }
  ],
  "suggested_followups": [
    "What specific solutions did users suggest?",
    "How does this compare across segments?"
  ]
}
```

---

## 7. API Design (Key Endpoints)

### Interviews
```
POST   /api/interviews/upload-url     â†’ Get signed GCS upload URL
POST   /api/interviews                â†’ Register uploaded file, start processing
GET    /api/interviews                â†’ List all interviews (with filters, pagination)
GET    /api/interviews/:id            â†’ Interview detail + transcript + insights
DELETE /api/interviews/:id            â†’ Delete interview + recalculate themes
POST   /api/interviews/:id/reanalyze  â†’ Re-run AI extraction
```

### Themes
```
GET    /api/themes                    â†’ List themes (sorted, paginated, top 10 + show more)
GET    /api/themes/:id                â†’ Theme detail (quotes, sources, segments)
PATCH  /api/themes/:id                â†’ Rename theme
```

### Insights
```
POST   /api/insights                  â†’ Manually add insight (user-created)
PATCH  /api/insights/:id              â†’ Edit category, title, theme assignment
DELETE /api/insights/:id              â†’ Dismiss insight (soft delete)
POST   /api/insights/:id/flag         â†’ Flag as uncertain
```

### Ask (Q&A)
```
POST   /api/ask                       â†’ Send question, get streaming response (SSE)
GET    /api/ask/conversations         â†’ List past conversations
GET    /api/ask/conversations/:id     â†’ Get conversation history
```

### Export
```
GET    /api/export/insights           â†’ Export all insights (markdown or PDF)
GET    /api/export/interview/:id      â†’ Export single interview + insights
GET    /api/export/all-data           â†’ Full data export (ZIP)
```

### Auth & Billing
```
POST   /api/auth/verify               â†’ Verify Firebase token, create/get user
GET    /api/billing/usage             â†’ Current usage stats
POST   /api/billing/create-checkout   â†’ Stripe checkout session
POST   /api/billing/webhook           â†’ Stripe webhook handler
```

### WebSocket
```
WS     /ws/processing                 â†’ Real-time processing status updates
```

---

## 8. Deployment Architecture (GCP)

> **Simplified for beta (50-100 users).** No Cloud DNS, no Load Balancer.
> Cloud Run handles HTTPS and custom domains natively.

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  GoDaddy DNS          â”‚
                    â”‚  spec10x.com           â”‚
                    â”‚  CNAME â†’ Cloud Run     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚              â”‚              â”‚
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
     â”‚  Cloud Run      â”‚ â”‚Cloud Runâ”‚ â”‚  Cloud Run      â”‚
     â”‚  (Frontend)     â”‚ â”‚(Backend â”‚ â”‚  (Workers)      â”‚
     â”‚  Next.js SSR    â”‚ â”‚ API)    â”‚ â”‚  Processing     â”‚
     â”‚  + auto-SSL     â”‚ â”‚ FastAPI â”‚ â”‚  jobs           â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚             â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                  â”‚
  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  Cloud SQL  â”‚   â”‚ Memorystore â”‚   â”‚  GCS         â”‚
  â”‚  PostgreSQL â”‚   â”‚ Redis       â”‚   â”‚  File uploadsâ”‚
  â”‚  + pgvector â”‚   â”‚             â”‚   â”‚              â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### DNS & Domain Setup (Simplified)

1. **Domain:** Buy `spec10x.com` on GoDaddy
2. **DNS:** In GoDaddy DNS, add a CNAME record pointing to Cloud Run's auto-generated URL
3. **SSL:** Cloud Run automatically provisions and renews Google-managed SSL certificates
4. **No Cloud DNS needed** â€” GoDaddy's DNS is sufficient
5. **No Load Balancer needed** â€” Cloud Run handles HTTPS termination natively

> **When to add a Load Balancer:** If we exceed ~1K concurrent users, need Cloud CDN caching, Cloud Armor DDoS protection, or static IP addresses. This is a v0.5+ concern, not v0.1.

### Cloud Run Configuration

| Service | vCPU | Memory | Min Instances | Max Instances | Timeout |
|---|---|---|---|---|---|
| Frontend (Next.js) | 1 | 512MB | 0 (scales to zero) | 3 | 300s |
| Backend (FastAPI) | 1 | 512MB | 1 (always warm) | 5 | 300s |
| Workers (Processing) | 2 | 2GB | 0 | 10 | 3600s (1 hour, for long transcriptions) |

**WebSocket support:** Cloud Run supports WebSockets natively (no special config). Max timeout 60 min per connection, up to 1000 concurrent connections per instance. For our beta (50-100 users), this is more than sufficient.

### Environment Setup

| Environment | Purpose | Cost Profile |
|---|---|---|
| **Development** | Local Docker Compose (PostgreSQL + pgvector, Redis, MinIO for GCS) | $0 |
| **Staging** | Cloud Run (min instances: 0), Cloud SQL (smallest instance) | ~$30/month |
| **Production** | Cloud Run (min instances: 1 for API), Cloud SQL, Memorystore | ~$80-180/month |

### CI/CD Pipeline (Cloud Build)

```
git push to main
  â†’ Cloud Build triggers
  â†’ Run tests (pytest backend, jest frontend)
  â†’ Build Docker images
  â†’ Push to Artifact Registry
  â†’ Deploy to Cloud Run (rolling update)
  â†’ Run health checks
  â†’ Notify Slack
```

---

## 9. Cost Estimates (v0.1, first 6 months)

### Fixed Infrastructure Costs (Beta: 50-100 users)

| Service | Spec | Monthly Cost |
|---|---|---|
| Cloud SQL (PostgreSQL 18) | db-f1-micro (1 vCPU shared, 614MB RAM) | ~$10 |
| Memorystore (Redis) | Basic, 1GB | $35 |
| Cloud Run (Backend API) | 1 vCPU, 512MB, min 1 instance | ~$15-25 |
| Cloud Run (Frontend) | 1 vCPU, 512MB, scales to zero | ~$5-15 |
| Cloud Run (Workers) | 2 vCPU, 2GB, scales to zero | ~$5-20 |
| Cloud Storage | First 5GB free, then $0.02/GB | ~$2 |
| **Total infrastructure** | | **~$72-107/month** |

> **Savings vs. original plan:** ~$80-100/month by removing Cloud DNS ($0.20/zone + queries) and Cloud Load Balancer ($18/month fixed + per-rule charges).

### Variable AI Costs (per-user activity, Vertex AI pricing)

| Service | Per Unit | Example (100 interviews/month) |
|---|---|---|
| Chirp 3 (transcription) | $0.016/min (60 min/month free) | 100 interviews Ã— 30 min avg = $48 |
| Gemini 2.5 Flash-Lite (extraction) | $0.10/1M input, $0.40/1M output | 100 interviews Ã— ~5K tokens = ~$0.05 input + ~$0.20 output |
| gemini-embedding-001 | $0.15/1M input tokens | 100 interviews Ã— ~10K tokens = ~$0.15 |
| Gemini 3 Flash (Q&A) | $0.50/1M input, $3.00/1M output | 500 queries Ã— ~10K tokens = ~$5 input + ~$15 output |
| **Total AI per 100 interviews** | | **~$68/month** |

> **Cost note:** The transcription cost ($48) is the biggest driver. Encouraging users to upload existing transcripts from Otter/Fireflies instead of raw audio reduces this to near-zero.

### Break-Even Analysis

| Customers | Revenue (mix of tiers) | Infrastructure | AI Costs | Profit |
|---|---|---|---|---|
| 10 (mostly free) | ~$150/month | $90 | $15 | **+$45** |
| 50 (20 paid) | ~$800/month | $120 | $120 | **+$560** |
| 200 (80 paid) | ~$3,200/month | $200 | $500 | **+$2,500** |

> Spec10x is profitable from **day one** with the simplified architecture. Even 10 customers with a few paid subscriptions covers costs.

---

## 10. v0.1 â†’ v1.0 Evolution Path

| Version | What Changes in the Stack |
|---|---|
| **v0.1** | Full stack as described above. Monolith backend, single DB |
| **v0.5** | Add integration connectors (Zendesk, Mixpanel) as new `services/connectors/` modules. Add `data_sources` table. Same DB, same infra |
| **v0.8** | Add spec generation service (new Gemini prompts). Add `specs`, `wireframes` tables. May need a dedicated worker pool for heavier AI tasks |
| **v1.0** | Add PM tool sync (webhook endpoints), task export, roadmap data. Consider splitting workers into a separate service. May migrate pgvector to dedicated vector DB (Qdrant) if scale demands. Consider GKE if Cloud Run limits hit |

### What WON'T Need to Change

- **Frontend framework** (Next.js) â€” just add pages and components
- **Backend framework** (FastAPI) â€” just add route modules and services
- **Database** (PostgreSQL) â€” just add tables via Alembic migrations
- **Auth** (Firebase) â€” stays the same
- **AI provider** (Vertex AI) â€” same SDK, new prompts, models auto-upgraded
- **Deployment** (Cloud Run) â€” scales automatically

### What MIGHT Change

- **Vector DB** â€” pgvector â†’ Qdrant/Weaviate if queries slow down at scale (>1M vectors)
- **Queue** â€” Redis/arq â†’ Cloud Tasks or Pub/Sub for more complex workflows
- **Deployment** â€” Cloud Run â†’ GKE if we need long-running WebSocket connections or GPU workers
- **Search** â€” Add Elasticsearch if full-text search across all data sources gets complex

---

## 11. Local Development Setup

```bash
# Prerequisites: Python 3.12+, Node 20+, Docker

# Clone and setup
git clone https://github.com/spec10x/spec10x.git
cd spec10x

# Start infrastructure (PostgreSQL, Redis, MinIO)
docker compose up -d

# Backend
cd backend
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
alembic upgrade head              # run migrations
uvicorn app.main:app --reload     # start API server

# Frontend
cd frontend
npm install
npm run dev                        # start Next.js dev server

# Environment variables needed:
# GEMINI_API_KEY, GCS_BUCKET, FIREBASE_PROJECT_ID,
# DATABASE_URL, REDIS_URL, STRIPE_SECRET_KEY
```

---

## 12. Security Considerations

| Area | Approach |
|---|---|
| **Authentication** | Firebase Auth JWT tokens verified on every API request |
| **Authorization** | Row-level: every query filtered by `user_id`. Users can ONLY see their own data |
| **File uploads** | Signed URLs with 15-min expiry, max file size enforced server-side |
| **API rate limiting** | Redis-based rate limiting per user (tied to plan limits) |
| **Data encryption** | At rest: Cloud SQL encryption (default). In transit: HTTPS everywhere |
| **PII** | Interview data stored in user-scoped rows. Full data deletion on account delete |
| **Secrets** | GCP Secret Manager for API keys. Never in code or env files |
| **CORS** | Strict: only `spec10x.com` and `localhost` in dev |
